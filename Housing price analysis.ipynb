{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA dumb group name - housing price prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#dummifying\">Dummifying</a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents\n",
    "1. <a href=\"#target\">Target</a><br>\n",
    "2. <a href=\"#missingness\">Missingness</a><br>\n",
    "3. <a href=\"#cleaning\">Data cleaning and preliminary feature engineering</a><br>\n",
    "4. <a href=\"#modelling\">Model fitting</a><br>\n",
    "    a. <a href=\"#diagnostics\">Diagnostics, multicollinearity, feature selection</a><br>\n",
    "    b. <a href=\"#linear models\">Linear models</a><br>\n",
    "      - <a href=\"#optimal features\">Optimal features and linear model re-fitting</a><br>\n",
    "      - <a href=\"#linear model results\">Linear model results</a><br>\n",
    " \n",
    " c. <a href=\"#non-linear models\">Non-linear models</a><br>\n",
    " d. <a href=\"#all results\">All Results</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import statsmodels as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the train and test data\n",
    "train_data = pd.read_csv(\"data/train.csv\", index_col = 0, encoding = \"utf-8\")\n",
    "sale_price = train_data[['SalePrice']]\n",
    "test_data = pd.read_csv(\"data/test.csv\", index_col = 0, encoding = \"utf-8\")\n",
    "test_data['SalePrice'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the train and test data for the moment, so manipulations are applied to both\n",
    "all_data = pd.concat([train_data, test_data], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"target\"></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Target is highly skewed! Use a transformation to correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare normality of target under no transformation, optimum box-cox and log\n",
    "fig1, ax1 = plt.subplots(figsize=(11.7, 8.27))\n",
    "prob1 = stats.probplot(sale_price['SalePrice'], dist=stats.norm, plot=ax1)\n",
    "ax1.set_title('Probplot against normal distribution')\n",
    "\n",
    "print(all(sale_price['SalePrice'] > 0))\n",
    "fig2, ax2 = plt.subplots(figsize=(11.7, 8.27))\n",
    "sale_price_log = stats.boxcox(sale_price, lmbda = 0)\n",
    "prob2 = stats.probplot(sale_price_log.flatten(), dist=stats.norm, plot=ax2)\n",
    "ax2.set_title('Probplot after log transformation')\n",
    "\n",
    "fig3, ax3 = plt.subplots(figsize=(11.7, 8.27))\n",
    "sale_price_bc, lmbda = stats.boxcox(sale_price)\n",
    "prob3 = stats.probplot(sale_price_bc.flatten(), dist=stats.norm, plot=ax3)\n",
    "ax3.set_title('Probplot after Box-Cox transformation')\n",
    "\n",
    "plt.show()\n",
    "# Optimal Lambda is -0.07692396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms of the lob and box-cos transformed target data\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(11.7, 8.27))\n",
    "ax0, ax1, = axes.flatten()\n",
    "ax0.hist(sale_price_log, density = True)\n",
    "ax1.hist(sale_price_bc, density = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The target data transformed by the logarithm (lambda = 0) looks pretty good and is more easily interpreted - continue with this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"missingness\"></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an overview of the feature set\n",
    "all_data.describe()\n",
    "# 37 numerical variables inc. SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.columns[all_data.isnull().any()]\n",
    "# 25 features with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the columns with missing data\n",
    "all_data.loc[:, ['MSZoning', 'LotFrontage', 'Alley', 'Utilities', 'Exterior1st',\n",
    "       'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond',\n",
    "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
    "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Electrical', 'BsmtFullBath',\n",
    "       'BsmtHalfBath', 'KitchenQual', 'Functional', 'FireplaceQu',\n",
    "       'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea',\n",
    "       'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature',\n",
    "       'SaleType']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing data combinations\n",
    "fig, ax = plt.subplots(figsize=(11.7, 8.27))\n",
    "sns.heatmap(train_data.loc[:, ['MSZoning', 'LotFrontage', 'Alley', 'Utilities', 'Exterior1st',\n",
    "       'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond',\n",
    "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
    "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Electrical', 'BsmtFullBath',\n",
    "       'BsmtHalfBath', 'KitchenQual', 'Functional', 'FireplaceQu',\n",
    "       'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea',\n",
    "       'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature',\n",
    "       'SaleType']].isnull(), cbar = False, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"cleaning\"></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning and preliminary feature selection\n",
    "Most appropriate method of imputation has been selected for each feature based on missingness quantity, pattern, feature characteristics and feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values from the basement data with random selections from the appropriate options\n",
    "np.random.seed(0)\n",
    "basement = all_data.loc[:,['BsmtQual', 'BsmtCond',\n",
    "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
    "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',]]\n",
    "basement[(basement.isnull().any(axis = 1)) & (basement.loc[:,'TotalBsmtSF'] != 0)] =\\\n",
    "basement[(basement.isnull().any(axis = 1)) & (basement.loc[:,'TotalBsmtSF'] != 0)].apply(lambda x: x.fillna(np.random.choice(x.dropna())), axis=0)\n",
    "\n",
    "# Replace the NA's that correspond to no garage with \"None\"\n",
    "basement.loc[basement.isnull().any(axis = 1),['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']] = \"None\"\n",
    "all_data.loc[:,['BsmtQual', 'BsmtCond',\n",
    "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
    "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',]] = basement\n",
    "\n",
    "# Remove the singular missing completely at random observation in the electrical column\n",
    "all_data = all_data.drop(all_data[all_data.loc[:,'Electrical'].isnull()].index[0], axis = 0)\n",
    "\n",
    "# Replace all NA values that actually mean no fireplaces with 'None'\n",
    "all_data.loc[(all_data['FireplaceQu'].isnull()) & (all_data['Fireplaces'] == 0),'FireplaceQu'] = \"None\"\n",
    "\n",
    "# Replace all NA values that actually mean no garage with 'None'\n",
    "all_data.loc[(all_data['GarageType'].isnull()) &(all_data['GarageArea'] == 0),'GarageType'] = 'None'\n",
    "all_data.loc[(all_data['GarageFinish'].isnull()) &(all_data['GarageArea'] == 0),'GarageFinish'] = 'None'\n",
    "all_data.loc[(all_data['GarageQual'].isnull()) &(all_data['GarageArea'] == 0),'GarageQual'] = 'None'\n",
    "\n",
    "# Impute for the very few missing values in the GarageQual and GarageFinish\n",
    "GarFin_index = (all_data[(all_data.GarageArea!=0) & (all_data.GarageFinish.isnull())]['GarageFinish']).index\n",
    "GarQual_index  = (all_data[(all_data.GarageArea!=0) & (all_data.GarageQual.isnull())]['GarageQual']).index\n",
    "all_data.loc[GarQual_index,'GarageQual'] = np.random.choice(['TA', 'Fa', 'Gd','Ex', 'Po'])\n",
    "all_data.loc[GarFin_index,'GarageFinish'] = np.random.choice(['Fin','RFn','Unf'])\n",
    "\n",
    "# Impute using the mean/median for the very few missing values in the other garage columns\n",
    "all_data.loc[(all_data['GarageYrBlt'].isnull()) &(all_data['GarageArea'] == 0),'GarageYrBlt'] = 'None'\n",
    "all_data.loc[2576,'GarageArea'] = all_data.GarageArea.mean()\n",
    "all_data.loc[2576,'GarageCars'] = all_data.GarageCars.mean()\n",
    "all_data.loc[[2126,2576],'GarageYrBlt'] = all_data.GarageYrBlt[all_data.GarageYrBlt != 'None'].median()\n",
    "\n",
    "# Replace all NA values that actualy mean no pool with \"None\"\n",
    "all_data.loc[(all_data['PoolQC'].isnull()) & (all_data['PoolArea'] == 0),'PoolQC'] = 'None'\n",
    "\n",
    "# Impute for the very few missing values in the PoolQC column\n",
    "poolna_index = (all_data[(all_data.PoolArea!=0) & (all_data.PoolQC.isnull())]['PoolQC']).index\n",
    "all_data.loc[poolna_index[0],'PoolQC'] = np.random.choice(['Ex','Gd','Fa'])\n",
    "all_data.loc[poolna_index[1],'PoolQC'] = np.random.choice(['Ex','Gd','Fa'])\n",
    "all_data.loc[poolna_index[2],'PoolQC'] = np.random.choice(['Ex','Gd','Fa'])\n",
    "all_data.loc[poolna_index,'PoolQC']\n",
    "\n",
    "# Replace all NA values that actualy mean no fence with \"None\"\n",
    "all_data['Fence'].fillna(value='None', inplace=True)\n",
    "\n",
    "# Replace the only NA value with the majority value Typ\n",
    "all_data['Functional'].fillna(value='Typ', inplace=True)\n",
    "\n",
    "# Replace the remaining couple of NA values in the BsmtBath columns with values that preserve the column means\n",
    "all_data.loc[2120, 'BsmtFullBath'] = 1\n",
    "all_data.loc[2188, 'BsmtFullBath'] = 0\n",
    "all_data['BsmtHalfBath'].fillna(value=0, inplace=True)\n",
    "\n",
    "# Replace all NA values that actualy mean no fence with \"None\"\n",
    "all_data.loc[(all_data.MiscFeature.isnull()) & (all_data.MiscVal == 0),'MiscFeature'] = 'None'\n",
    "\n",
    "# Replace the missing value in MicsFeature according to its corresponding MiscValue\n",
    "all_data.loc[all_data.MiscFeature.isnull(), 'MiscFeature'] = 'Gar2'\n",
    "\n",
    "# Replace missing values in the Exterior columns with majority values\n",
    "all_data.loc[all_data.Exterior1st.isnull(),'Exterior1st'] = 'VinylSd'\n",
    "all_data.loc[all_data.Exterior2nd.isnull(),'Exterior2nd'] = 'VinylSd'\n",
    "all_data.loc[all_data.MSZoning.isnull(),'MSZoning'] = 'RL'\n",
    "all_data.loc[all_data.SaleType.isnull(),'SaleType'] = 'WD'\n",
    "all_data.loc[all_data.KitchenQual.isna(), 'KitchenQual'] = 'Ta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For those columns with a larger number of truly missing values, randomly impute\n",
    "all_lf_index = (all_data[all_data.LotFrontage.isnull()]).index\n",
    "for idx in all_lf_index:\n",
    "    all_data.loc[idx,'LotFrontage'] = np.random.choice(all_data.LotFrontage.dropna(), replace = False)\n",
    "\n",
    "all_mvt_index = (all_data[all_data.MasVnrType.isnull()]).index\n",
    "for idx in all_mvt_index:\n",
    "    all_data.loc[idx,'MasVnrType'] = np.random.choice(['None', 'BrkFace', 'Stone'], replace = True)\n",
    "\n",
    "all_mva_index = (all_data[all_data.MasVnrArea.isnull()]).index\n",
    "for idx in all_mva_index:\n",
    "    all_data.loc[idx,'MasVnrArea'] = np.random.choice(all_data.MasVnrArea.dropna(), replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a copy of the dataframe at this point (before dropping any columns) \n",
    "# Get rid of those columns that take almost exlcusively one value, and hence will ofer little to no information\n",
    "all_data_no_drop = all_data.copy()\n",
    "all_data = all_data.drop([\"Street\",\"Alley\",\"Utilities\", \"BldgType\", 'HouseStyle', 'YearBuilt', 'RoofMatl', 'BsmtFinSF1', 'BsmtFinSF2', 'Heating', 'GarageCond'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all NaN's have been removed\n",
    "all_data.loc[:,all_data.isnull().any()].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine some columns to further reduce down feature space\n",
    "all_data[\"OthrRmsAbvGrd\"] = all_data.TotRmsAbvGrd - all_data.KitchenAbvGr - all_data.BedroomAbvGr\n",
    "all_data['Total_Porch_SF'] = all_data['WoodDeckSF']+all_data['OpenPorchSF']+all_data['EnclosedPorch']+all_data['3SsnPorch']+all_data['ScreenPorch']\n",
    "all_data['TotalSf'] = all_data['TotalBsmtSF'] + all_data['GrLivArea'] + all_data['LowQualFinSF']\n",
    "all_data['TotalBath'] = all_data['FullBath'] + all_data['BsmtFullBath'] + (0.5*all_data['HalfBath']) + (0.5*all_data['BsmtHalfBath'])\n",
    "all_data['Pool'] = all_data['PoolArea'].apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "# These are being dropped because they're combined into new columns or because of very little correlation\n",
    "all_data = all_data.drop(['TotRmsAbvGrd', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', \\\n",
    "                          'WoodDeckSF', 'OpenPorchSF', '2ndFlrSF', '1stFlrSF', 'TotalBsmtSF',\\\n",
    "                          'Condition1','Condition2','FullBath','BsmtFullBath','HalfBath','BsmtHalfBath',\\\n",
    "                          'BsmtUnfSF','MiscVal','LowQualFinSF','PoolArea','PoolQC','MiscFeature','LandSlope',\\\n",
    "                          'GarageYrBlt','GrLivArea','GarageCars'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"dummifying\"></a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify all categorical columns, drop one from each set of dummies and the original categorical column\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "all_categorical = all_data.select_dtypes(exclude=[np.number]).columns\n",
    "# mergedCat = all_data[all_categorical]\n",
    "# mergedCat = pd.get_dummies(mergedCat,drop_first=True)\n",
    "# dummified_full = pd.concat([all_data,mergedCat],axis=1)\n",
    "# dummified_full = dummified_full.drop(all_categorical,axis=1)\n",
    "dummified_full = pd.read_csv(\"data/train_sam.csv\", sep='\\t')\n",
    "dummified_full = dummified_full.drop('GarageYrBlt', axis = 1)\n",
    "dummified_full = dummified_full.drop(all_categorical,axis=1)\n",
    "dummified_full = dummified_full.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate non-dummified feature correlation with the target\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "all_data[all_data.loc[:,'SalePrice'] != 0].corr().loc['SalePrice'].abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Investigate dummified feature correlation with the target\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "dummified_full[dummified_full.loc[:,'SalePrice'] != 0].corr().loc['SalePrice'].abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"modelling\"></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"diagnostics\"></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnostics, multicollinearity, feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for returning adjusted R squared, as well as checking the assumptions of linear regression\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "def diagnostics(model,x,y):\n",
    "    # Making adjusted R squared\n",
    "    yhat = model.predict(x)\n",
    "    SS_Residual = sum((y-yhat)**2)\n",
    "    SS_Total = sum((y-np.mean(y))**2)\n",
    "    r_squared = 1-(float(SS_Residual)/float(SS_Total))\n",
    "    adjusted_r_squared = 1 - ((1-r_squared)*(len(y)-1))/(len(y)-x.shape[1]-1)\n",
    "    return(adjusted_r_squared)\n",
    "    \n",
    "    # Testing assumptions\n",
    "    ## Homoscedasticity and independent errors\n",
    "    fig2, ax2 = plt.subplots(figsize=(11.7, 8.27))\n",
    "    sns.scatterplot(x = yhat, y = y-yhat, ax=ax2).set_title(\"Residuals vs actual values\")\n",
    "    plt.xlabel(\"Actual values of target\")\n",
    "    plt.ylabel(\"Value of residuals\")\n",
    "    print(\"Durbin-Watson test statistic: {}\".format(sm.stats.stattools.durbin_watson(resids = y-yhat)))\n",
    "    \n",
    "    ## Normality of residuals\n",
    "    fig1, ax1 = plt.subplots(figsize=(11.7, 8.27))\n",
    "    stats.probplot(y-yhat, dist=stats.norm, plot=ax1)\n",
    "    \n",
    "    # Adjusted R squared    \n",
    "    print(\"Adjusted R^2: {}\".format(adjusted_r_squared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-split the all_data frame into train and test sets\n",
    "train = dummified_full[dummified_full.SalePrice > 0]\n",
    "test = dummified_full[dummified_full.SalePrice == 0]\n",
    "test = test.drop('SalePrice',axis=1)\n",
    "\n",
    "X_train = train.drop('SalePrice',axis=1)\n",
    "Y_train = np.log(train.SalePrice)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use feature ranking with recursive feature elimination and cross-validation from Sklearn\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import linear_model\n",
    "\n",
    "ols = linear_model.LinearRegression()\n",
    "rfecv = RFECV(estimator=ols, step=1, cv=KFold(10),scoring='r2')\n",
    "rfecv.fit(x_train, y_train)\n",
    "\n",
    "house_features = rfecv.support_\n",
    "dummified_full.iloc[:,~house_features] #feature selection from RFECV method, columns to possibly drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Investigate multi-collinearity between non-dummified features\n",
    "temp = all_data[all_data.select_dtypes(include=[np.number]).columns].drop('SalePrice',axis=1)\n",
    "\n",
    "scores = {}\n",
    "ols2 = linear_model.LinearRegression()\n",
    "from sklearn.metrics import r2_score\n",
    "for feature_name in temp.columns:\n",
    "                dummified_full2     = temp.copy()\n",
    "                feature = dummified_full2[feature_name].copy()\n",
    "                dummified_full2.drop(feature_name, axis=1, inplace=True)\n",
    "                ols2.fit(dummified_full2, feature)\n",
    "                scores[feature_name] = ols2.score(dummified_full2, feature)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize multi-collinearity between non-dummified features\n",
    "plt.figure(figsize=(15,7))\n",
    "g = sns.barplot(x='index', y='R2', data=pd.DataFrame(scores, index=['R2']).T.reset_index())\n",
    "plt.xticks(rotation=70)\n",
    "plt.title('$R^2$ of a continuous feature against the other features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"linear models\"></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a simple multiple linear regression as a baseline, even though multi-collinearity \n",
    "# and curse of dimensionlity (many features) indicates this may be a bad choice\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet, LinearRegression,HuberRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "linR = LinearRegression()\n",
    "linR.fit(x_train, y_train)\n",
    "linR_scores = cross_val_score(linR, x_train, y_train, cv=5)\n",
    "\n",
    "Results_linR = pd.DataFrame({'CV':np.mean(linR_scores), \n",
    "                        'Adjusted': diagnostics(linR,x_train,y_train),\n",
    "                        'Train':linR.score(x_train, y_train), \n",
    "                        'Test':linR.score(x_test, y_test)}, index = ['MLR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a Huber Regression (with a grid search) - this should handle any outliers well \n",
    "hubR = HuberRegressor()\n",
    "params = {'alpha':10**np.linspace(-2,2,10), 'epsilon': np.linspace(1,2,10)}\n",
    "grid = GridSearchCV(estimator=hubR, param_grid=params, cv=5)\n",
    "grid.fit(x_train, y_train)\n",
    "print(grid.best_params_)\n",
    "\n",
    "hubR_optimal = grid.best_estimator_\n",
    "Results_hubr = pd.DataFrame({'CV':grid.best_score_,\n",
    "                       'Adjusted': diagnostics(hubR_optimal,x_train,y_train),\n",
    "                       'Train':hubR_optimal.score(x_train, y_train),\n",
    "                       'Test':hubR_optimal.score(x_test, y_test)}, index = ['Huber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Try a Lasso penalized regression - this has the advantage of helping with feature selection\n",
    "# Find the optimum lambda\n",
    "lr = Lasso(normalize=True)\n",
    "\n",
    "params = {'alpha':10**np.linspace(-4,-1,100)}\n",
    "grid = GridSearchCV(estimator=lr, param_grid=params, cv=5)\n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "lr_optimal = grid.best_estimator_\n",
    "\n",
    "Results_lasso = pd.DataFrame({'CV':grid.best_score_,\n",
    "                       'Adjusted': diagnostics(lr_optimal,x_train,y_train),\n",
    "                       'Train':lr_optimal.score(x_train, y_train),\n",
    "                       'Test':lr_optimal.score(x_test, y_test)}, index = ['Lasso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bootstrapping to generate confidence intervals for the coefficient estimates from the\n",
    "# above regression. Any that span zero could be targets for removal\n",
    "coefs = {}\n",
    "intercepts = {}\n",
    "\n",
    "for i in range(1000):\n",
    "    rIndex = np.random.choice(x_train.index, 400, replace=False) # randomly select 400 samples 1000 times   \n",
    "    sampled_x = x_train.loc[rIndex]\n",
    "    sampled_y = y_train.loc[rIndex]\n",
    "\n",
    "    grid.best_estimator_.fit(sampled_x, sampled_y)\n",
    "    coefs[i] = grid.best_estimator_.coef_\n",
    "    intercepts[i] = grid.best_estimator_.intercept_\n",
    "coefs = pd.DataFrame(coefs)\n",
    "intercepts= pd.Series(intercepts)\n",
    "coefs_avg = coefs.apply('mean', axis =1)\n",
    "coefs_sd = coefs.apply('std',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "coefs_lowlim = coefs_avg - 2*coefs_sd\n",
    "coefs_uplim = coefs_avg + 2*coefs_sd\n",
    "coefs_conf = pd.DataFrame({'lower': coefs_lowlim,'upper':coefs_uplim, 'boundary': np.where((coefs_lowlim <0) & (coefs_uplim >0),0,1)})\n",
    "features_index = coefs_conf[coefs_conf.lower >0].index\n",
    "x_train.columns[features_index]\n",
    "# coefs_conf.loc[:,['lower','upper']].plot.line() # Plot if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Plot the magnitudes of the coefficients from the optimum Lasso model that are non-zero\n",
    "# plt.figure(figsize=(15,7))\n",
    "# feature_coefs = list(zip(x_train.columns[lr_optimal.coef_!=0], abs(lr_optimal.coef_[lr_optimal.coef_!=0])))\n",
    "# dtype = [('feature', 'S10'), ('coefs', 'float')]\n",
    "# feature_coefs = np.array(feature_coefs, dtype=dtype)\n",
    "# feature_sort = np.sort(feature_coefs, order='coefs')[::-1]\n",
    "# name, score = zip(*list(feature_sort))\n",
    "# opt_coefs = pd.DataFrame({'name':name,'score':score})\n",
    "# plt.bar(x=opt_coefs.name, height=opt_coefs.score)\n",
    "# plt.xticks(rotation=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a ridge regression\n",
    "# Find the optimum lambda\n",
    "rd = Ridge(normalize=True)\n",
    "\n",
    "params = {'alpha':10**np.linspace(-2,2,100)}\n",
    "grid = GridSearchCV(estimator=rd,param_grid=params,cv=5)\n",
    "\n",
    "grid.fit(x_train,y_train)\n",
    "print(grid.best_params_)\n",
    "rd_optimal = grid.best_estimator_\n",
    "\n",
    "Results_ridge = pd.DataFrame({'CV':grid.best_score_,\n",
    "                       'Adjusted': diagnostics(rd_optimal,x_train,y_train),\n",
    "                       'Train':rd_optimal.score(x_train, y_train),\n",
    "                       'Test':rd_optimal.score(x_test, y_test)}, index = ['Ridge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try an elasticnet regression\n",
    "# FInd the optimum lambda and rho\n",
    "en = ElasticNet(max_iter=10000,normalize=True)\n",
    "\n",
    "params = {'alpha':10**np.linspace(-4,0,20),'l1_ratio':np.linspace(0.00001,0.001,20)}\n",
    "grid = GridSearchCV(estimator=en,param_grid=params,cv=5)\n",
    "\n",
    "grid.fit(x_train,y_train)\n",
    "print(grid.best_params_)\n",
    "en_optimal = grid.best_estimator_\n",
    "\n",
    "Results_en = pd.DataFrame({'CV': grid.best_score_,\n",
    "                       'Adjusted': diagnostics(en_optimal,x_train,y_train),\n",
    "                       'Train':en_optimal.score(x_train, y_train),\n",
    "                       'Test':en_optimal.score(x_test, y_test)}, index = ['ElasticNet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle Submission #1\n",
    "# Using the results of the above, get a baseline score from submitting the elasticnet \n",
    "# model, with no additional feature selection (other than that effected by the L1 penalty)\n",
    "sub1 = pd.DataFrame(np.exp(grid.predict(test)),index=test.index+1,columns=['SalePrice'])\n",
    "sub1.to_csv('sub1.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"optimal features\"></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal feature selection and model re-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the development of the model coefficients in Lasso regression\n",
    "alphas = 10**np.linspace(-6,-2,100)\n",
    "lr.set_params(normalize=True)\n",
    "coefs  = []\n",
    "\n",
    "for alpha in alphas:\n",
    "        lr.set_params(alpha=alpha)\n",
    "        lr.fit(x_train, y_train)  \n",
    "        coefs.append(lr.coef_)\n",
    "        \n",
    "coefs = pd.DataFrame(coefs, index = alphas, columns = x_train.columns)\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "for name in coefs.columns:\n",
    "    plt.plot(coefs.index, coefs[name], label=name)\n",
    "\n",
    "plt.xlabel(r'hyperparameter $\\lambda$')\n",
    "plt.ylabel(r'slope values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the ~10 coefficients that take the longest to go to zero\n",
    "coefs[(coefs.index>0.001)][coefs[(coefs.index>0.001)]!=0].notnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  - The optimal_features set below is made using the results of the above cell. \n",
    "######  - Optimal_features_2 contains the coefficients that are non-zero at the optimum lambda found from the lasso grid search. \n",
    "###### - Optimal_features_3 contains from the coefficients of the optimum lasso model with confidence intervals that do not span zero "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new feature spaces using only those features that Lasso regression suggests have the\n",
    "# most explanatory power\n",
    "optimal_features = x_train.loc[:,['OverallQual','YearRemodAdd','GarageArea','Fireplaces','OthrRmsAbvGrd','TotalBath','MSZoning_RM','MSZoning_RL','MSZoning_RH','MSZoning_FV','CentralAir_Y','FireplaceQu_Gd','FireplaceQu_TA','TotalSf']]\n",
    "optimal_features2 = x_train.loc[:,x_train.columns[lr_optimal.coef_!=0]]\n",
    "optimal_features3 = x_train.loc[:,x_train.columns[features_index]]\n",
    "optimal_features_test = test.loc[:,['OverallQual','YearRemodAdd','GarageArea','Fireplaces','OthrRmsAbvGrd','TotalBath','MSZoning_RM','MSZoning_RL','MSZoning_RH','MSZoning_FV','CentralAir_Y','FireplaceQu_Gd','FireplaceQu_TA','TotalSf']]\n",
    "optimal_features_test2 = test.loc[:,x_train.columns[lr_optimal.coef_!=0]]\n",
    "optimal_features_test3 = test.loc[:,x_train.columns[features_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run linear regression with a reduced feature set\n",
    "linR = LinearRegression()\n",
    "linR.fit(optimal_features,y_train)\n",
    "linR_scores = cross_val_score(linR,optimal_features,y_train,cv=5)\n",
    "Results_linR_opt = pd.DataFrame({'CV':np.mean(linR_scores), \n",
    "                        'Adjusted': diagnostics(linR, optimal_features,y_train),\n",
    "                        'Train':linR.score(optimal_features, y_train), \n",
    "                        'Test':linR.score(x_test.loc[:,list(optimal_features.columns)], y_test)}, \n",
    "                                index = ['MLR_opt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run linear regression with a second reduced feature set\n",
    "linR = LinearRegression()\n",
    "linR.fit(optimal_features2,y_train)\n",
    "linR_scores = cross_val_score(linR,optimal_features2,y_train,cv=5)\n",
    "Results_linR_opt2 = pd.DataFrame({'CV':np.mean(linR_scores), \n",
    "                        'Adjusted': diagnostics(linR, optimal_features2,y_train),\n",
    "                        'Train':linR.score(optimal_features2, y_train), \n",
    "                        'Test':linR.score(x_test.loc[:,list(optimal_features2.columns)], y_test)}, \n",
    "                                 index = ['MLR_opt2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run linear regression with a third reduced feature set\n",
    "linR = LinearRegression()\n",
    "linR.fit(optimal_features3,y_train)\n",
    "linR_scores = cross_val_score(linR,optimal_features3,y_train,cv=5)\n",
    "Results_linR_opt3 = pd.DataFrame({'CV':np.mean(linR_scores), \n",
    "                        'Adjusted': diagnostics(linR, optimal_features3,y_train),\n",
    "                        'Train':linR.score(optimal_features3, y_train), \n",
    "                        'Test':linR.score(x_test.loc[:,list(optimal_features3.columns)], y_test)}, \n",
    "                                 index = ['MLR_opt3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Huber Regression with a reduced feature set\n",
    "hubR = HuberRegressor()\n",
    "params = {'alpha':10**np.linspace(-4,2,10), 'epsilon': np.linspace(1,5,50)}\n",
    "grid = GridSearchCV(estimator=hubR, param_grid=params, cv=5)\n",
    "grid.fit(optimal_features, y_train)\n",
    "hubR_optimal = grid.best_estimator_\n",
    "\n",
    "Results_hubR_opt = pd.DataFrame({'CV':grid.best_score_, \n",
    "                        'Adjusted': diagnostics(hubR_optimal, optimal_features, y_train),\n",
    "                        'Train':hubR_optimal.score(optimal_features, y_train), \n",
    "                        'Test':hubR_optimal.score(x_test.loc[:,list(optimal_features.columns)], y_test)}, \n",
    "                                index = ['hubR_opt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Huber Regression with a second reduced feature set\n",
    "hubR = HuberRegressor()\n",
    "params = {'alpha':10**np.linspace(-4,2,10), 'epsilon': np.linspace(1,5,50)}\n",
    "grid = GridSearchCV(estimator=hubR, param_grid=params, cv=5)\n",
    "grid.fit(optimal_features2, y_train)\n",
    "hubR_optimal = grid.best_estimator_\n",
    "\n",
    "Results_hubR_opt2 = pd.DataFrame({'CV': grid.best_score_, \n",
    "                        'Adjusted': diagnostics(hubR_optimal, optimal_features2, y_train),\n",
    "                        'Train':hubR_optimal.score(optimal_features2, y_train), \n",
    "                        'Test':hubR_optimal.score(x_test.loc[:,list(optimal_features2.columns)], y_test)}, \n",
    "                                index = ['hubR_opt_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Huber Regression with a third reduced feature set\n",
    "hubR = HuberRegressor()\n",
    "params = {'alpha':10**np.linspace(-2,2,10), 'epsilon': np.linspace(1,5,50)}\n",
    "grid = GridSearchCV(estimator=hubR, param_grid=params, cv=5)\n",
    "grid.fit(optimal_features3, y_train)\n",
    "hubR_optimal = grid.best_estimator_\n",
    "\n",
    "Results_hubR_opt3 = pd.DataFrame({'CV':grid.best_score_, \n",
    "                        'Adjusted': diagnostics(hubR_optimal, optimal_features3, y_train),\n",
    "                        'Train':hubR_optimal.score(optimal_features3, y_train), \n",
    "                        'Test':hubR_optimal.score(x_test.loc[:,list(optimal_features3.columns)], y_test)}, \n",
    "                                index = ['hubR_opt_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso regression with a reduced feature set\n",
    "lr = Lasso(normalize=True)\n",
    "\n",
    "params = {'alpha':10**np.linspace(-6,-3,100)}\n",
    "grid = GridSearchCV(estimator=lr,param_grid=params,cv=5)\n",
    "\n",
    "grid.fit(optimal_features,y_train)\n",
    "lr_optimal = grid.best_estimator_\n",
    "\n",
    "Results_lasso_opt = pd.DataFrame({'CV':grid.best_score_,\n",
    "                       'Adjusted': diagnostics(lr_optimal,optimal_features,y_train),\n",
    "                       'Train':lr_optimal.score(optimal_features, y_train),\n",
    "                       'Test':lr_optimal.score(x_test.loc[:,list(optimal_features.columns)], y_test)}, \n",
    "                                  index = ['Lasso_opt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso regression with a second reduced feature set\n",
    "lr = Lasso(normalize=True)\n",
    "\n",
    "params = {'alpha':10**np.linspace(-6,-3,100)}\n",
    "grid = GridSearchCV(estimator=lr,param_grid=params,cv=5)\n",
    "\n",
    "grid.fit(optimal_features2,y_train)\n",
    "lr_optimal = grid.best_estimator_\n",
    "\n",
    "Results_lasso_opt2 = pd.DataFrame({'CV':grid.best_score_,\n",
    "                       'Adjusted': diagnostics(lr_optimal,optimal_features2,y_train),\n",
    "                       'Train':lr_optimal.score(optimal_features2, y_train),\n",
    "                       'Test':lr_optimal.score(x_test.loc[:,list(optimal_features2.columns)], y_test)}, \n",
    "                                  index = ['Lasso_opt_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Lasso regression with a third reduced feature set\n",
    "lr = Lasso(normalize=True)\n",
    "\n",
    "params = {'alpha':10**np.linspace(-6,-3,100)}\n",
    "grid = GridSearchCV(estimator=lr,param_grid=params,cv=5)\n",
    "\n",
    "grid.fit(optimal_features3,y_train)\n",
    "lr_optimal = grid.best_estimator_\n",
    "\n",
    "Results_lasso_opt3 = pd.DataFrame({'CV':grid.best_score_,\n",
    "                       'Adjusted': diagnostics(lr_optimal,optimal_features3,y_train),\n",
    "                       'Train':lr_optimal.score(optimal_features3, y_train),\n",
    "                       'Test':lr_optimal.score(x_test.loc[:,list(optimal_features3.columns)], y_test)}, \n",
    "                                  index = ['Lasso_opt_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Ridge regression with a reduced feature set\n",
    "rd = Ridge(normalize=True)\n",
    "\n",
    "params = {'alpha':10**np.linspace(-4,2,100)}\n",
    "grid = GridSearchCV(estimator=rd,param_grid=params,cv=5)\n",
    "\n",
    "grid.fit(optimal_features,y_train)\n",
    "rd_optimal = grid.best_estimator_\n",
    "\n",
    "Results_ridge_opt = pd.DataFrame({'CV':grid.best_score_,\n",
    "                       'Adjusted': diagnostics(rd_optimal,optimal_features,y_train),\n",
    "                       'Train':rd_optimal.score(optimal_features, y_train),\n",
    "                       'Test':rd_optimal.score(x_test.loc[:,list(optimal_features.columns)], y_test)}, \n",
    "                                  index = ['Ridge_opt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Ridge regression with a second reduced feature set\n",
    "rd = Ridge(normalize=True)\n",
    "\n",
    "params = {'alpha':10**np.linspace(-4,2,100)}\n",
    "grid = GridSearchCV(estimator=rd,param_grid=params,cv=5)\n",
    "\n",
    "grid.fit(optimal_features2,y_train)\n",
    "rd_optimal = grid.best_estimator_\n",
    "\n",
    "Results_ridge_opt2 = pd.DataFrame({'CV':grid.best_score_,\n",
    "                       'Adjusted': diagnostics(rd_optimal,optimal_features2,y_train),\n",
    "                       'Train':rd_optimal.score(optimal_features2, y_train),\n",
    "                       'Test':rd_optimal.score(x_test.loc[:,list(optimal_features2.columns)], y_test)}, \n",
    "                                  index = ['Ridge_opt_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Ridge regression with a third reduced feature set\n",
    "rd = Ridge(normalize=True)\n",
    "\n",
    "params = {'alpha':10**np.linspace(-4,2,100)}\n",
    "grid = GridSearchCV(estimator=rd,param_grid=params,cv=5)\n",
    "\n",
    "grid.fit(optimal_features3,y_train)\n",
    "rd_optimal = grid.best_estimator_\n",
    "\n",
    "Results_ridge_opt3 = pd.DataFrame({'CV':grid.best_score_,\n",
    "                       'Adjusted': diagnostics(rd_optimal,optimal_features3,y_train),\n",
    "                       'Train':rd_optimal.score(optimal_features3, y_train),\n",
    "                       'Test':rd_optimal.score(x_test.loc[:,list(optimal_features3.columns)], y_test)}, \n",
    "                                  index = ['Ridge_opt_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle Submission #2\n",
    "# Compare the previous submission to the result obtained from the Ridge regression with\n",
    "# the optimal_features reduced feature set\n",
    "sub2 = pd.DataFrame(np.exp(grid.predict(optimal_features_test)),index=optimal_features_test.index+1,columns=['SalePrice'])\n",
    "sub2.to_csv('sub2.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run elasticnet regression with a reduced feature set\n",
    "en = ElasticNet(max_iter=10000,normalize=True)\n",
    "\n",
    "params = {'alpha':10**np.linspace(-5,-3,20),'l1_ratio':np.linspace(0.001,1,20)}\n",
    "grid = GridSearchCV(estimator=en,param_grid=params,cv=5)\n",
    "\n",
    "grid.fit(optimal_features,y_train)\n",
    "en_optimal = grid.best_estimator_\n",
    "\n",
    "Results_en_opt = pd.DataFrame({'CV':grid.best_score_, \n",
    "                        'Adjusted': diagnostics(en_optimal,optimal_features,y_train),\n",
    "                        'Train':en_optimal.score(optimal_features, y_train), \n",
    "                        'Test':en_optimal.score(x_test.loc[:,list(optimal_features.columns)], y_test)}, \n",
    "                               index = ['ElasticNet_opt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run elasticnet regression with a second reduced feature set\n",
    "en = ElasticNet(max_iter=10000,normalize=True)\n",
    "\n",
    "params = {'alpha':10**np.linspace(-5,-3,20),'l1_ratio':np.linspace(0.001,1,20)}\n",
    "grid = GridSearchCV(estimator=en,param_grid=params,cv=5)\n",
    "\n",
    "grid.fit(optimal_features2,y_train)\n",
    "en_optimal = grid.best_estimator_\n",
    "\n",
    "Results_en_opt2 = pd.DataFrame({'CV':grid.best_score_, \n",
    "                        'Adjusted': diagnostics(en_optimal,optimal_features2,y_train),\n",
    "                        'Train':en_optimal.score(optimal_features2, y_train), \n",
    "                        'Test':en_optimal.score(x_test.loc[:,list(optimal_features2.columns)], y_test)}, \n",
    "                               index = ['ElasticNet_opt2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run elasticnet regression with a third reduced feature set\n",
    "en = ElasticNet(max_iter=10000,normalize=True)\n",
    "\n",
    "params = {'alpha':10**np.linspace(-5,-3,20),'l1_ratio':np.linspace(0.001,1,20)}\n",
    "grid = GridSearchCV(estimator=en,param_grid=params,cv=5)\n",
    "\n",
    "grid.fit(optimal_features3,y_train)\n",
    "en_optimal = grid.best_estimator_\n",
    "\n",
    "Results_en_opt3 = pd.DataFrame({'CV':grid.best_score_, \n",
    "                        'Adjusted': diagnostics(en_optimal,optimal_features3,y_train),\n",
    "                        'Train':en_optimal.score(optimal_features3, y_train), \n",
    "                        'Test':en_optimal.score(x_test.loc[:,list(optimal_features3.columns)], y_test)}, \n",
    "                               index = ['ElasticNet_opt3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"linear model results\"></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_results = pd.concat([Results_linR, Results_hubr, Results_lasso, Results_ridge, Results_en,\n",
    "                                  Results_linR_opt, Results_linR_opt2, Results_linR_opt3,\n",
    "                                  Results_hubR_opt, Results_hubR_opt2,\n",
    "                                  Results_lasso_opt, Results_lasso_opt2, Results_lasso_opt3,\n",
    "                                  Results_ridge_opt, Results_ridge_opt2, Results_ridge_opt3, \n",
    "                                  Results_en_opt, Results_en_opt2, Results_en_opt3], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kaggle Submission #4\n",
    "# COmpare the previous elasticnet submission to this one, using a different reduced feature set\n",
    "sub4 = pd.DataFrame(np.exp(grid.predict(optimal_features_test2)),index=optimal_features_test2.index+1,columns=['SalePrice'])\n",
    "sub4.to_csv('sub4.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kaggle Submission #5\n",
    "# Using the bootstrapped values on the lasso regression\n",
    "sub5 = pd.DataFrame(np.exp(grid.predict(optimal_features_test3)),index=optimal_features_test3.index+1,columns=['SalePrice'])\n",
    "sub5.to_csv('sub5.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"non-linear models\"></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeRegressor()\n",
    "\n",
    "grid_para_tree = [{\n",
    "    \"min_samples_leaf\": range(1, 10),\n",
    "    \"min_samples_split\": np.linspace(start=2, stop=60, num=15, dtype=int)\n",
    "}]\n",
    "tree_model.set_params(random_state=108)\n",
    "grid_search_tree = GridSearchCV(tree_model, grid_para_tree, cv=10, scoring='r2', n_jobs=-1)\n",
    "%time grid_search_tree.fit(x_train, y_train)\n",
    "\n",
    "best_tree_model = grid_search_tree.best_estimator_\n",
    "print(grid_search_tree.best_params_)\n",
    "\n",
    "Results_decisiontree = pd.DataFrame({'CV':grid_search_tree.best_score_,\n",
    "                       'Adjusted': diagnostics(best_tree_model,x_train,y_train),\n",
    "                       'Train':best_tree_model.score(x_train, y_train),\n",
    "                       'Test':best_tree_model.score(x_test, y_test)}, \n",
    "                                    index = ['Decision_tree'])\n",
    "Results_decisiontree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle submission 3\n",
    "# Compare how the tree model does, relative to all the linear models previously\n",
    "sub4 = pd.DataFrame(np.exp(grid_search_tree.predict(test)),index=test.index+1,columns=['SalePrice'])\n",
    "sub4.to_csv('sub4.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a Random Forest Model\n",
    "from sklearn import ensemble\n",
    "\n",
    "randomForest = ensemble.RandomForestRegressor()\n",
    "\n",
    "grid_para_forest = [{'n_estimators': [25,50,100],'min_samples_leaf':range(1,10),'min_samples_split':np.linspace(2,30,15,dtype=int),'random_state':[42]}]\n",
    "\n",
    "grid_search_forest = GridSearchCV(randomForest,grid_para_forest,scoring='r2',cv=5,n_jobs=-1)\n",
    "%time grid_search_forest.fit(x_train,y_train)\n",
    "\n",
    "best_forest_model = grid_search_forest.best_estimator_\n",
    "print(grid_search_forest.best_params_)\n",
    "\n",
    "Results_forest = pd.DataFrame({'CV':grid_search_forest.best_score_,\n",
    "                       'Adjusted': diagnostics(best_forest_model,x_train,y_train),\n",
    "                       'Train':best_forest_model.score(x_train, y_train),\n",
    "                       'Test':best_forest_model.score(x_test, y_test)}, \n",
    "                              index = ['Random_forest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have implemented some feature selection, but a strength of tree/forest models is their ability to identify those features that contribute most to predicting a given target. Hence make a second input data set, without dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify the data set with no columns dropped\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "all_categorical_rf = all_data_no_drop.select_dtypes(exclude=[np.number]).columns\n",
    "mergedCat_rf = all_data_no_drop[all_categorical_rf]\n",
    "mergedCat_rf = pd.get_dummies(mergedCat_rf,drop_first=True)\n",
    "dummified_full_rf = pd.concat([all_data_no_drop,mergedCat_rf],axis=1)\n",
    "dummified_full_rf = dummified_full_rf.drop(all_categorical_rf,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data with no columns dropped into train and test\n",
    "train_rf = dummified_full_rf[dummified_full_rf.SalePrice > 0]\n",
    "test_rf = dummified_full_rf[dummified_full_rf.SalePrice == 0]\n",
    "test = test_rf.drop('SalePrice',axis=1)\n",
    "\n",
    "X_train_rf = train_rf.drop('SalePrice',axis=1)\n",
    "Y_train_rf = np.log(train_rf.SalePrice)\n",
    "\n",
    "# This section is useful to create dataframe comparing our train scores to the test scores\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_rf, x_test_rf, y_train_rf, y_test_rf = train_test_split(X_train_rf, Y_train_rf, test_size=0.2, random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run a Random Forest Model on the data with no columns dropped\n",
    "from sklearn import ensemble\n",
    "\n",
    "randomForest = ensemble.RandomForestRegressor()\n",
    "\n",
    "grid_para_forest = [{'n_estimators': [25,50,100],'min_samples_leaf':range(1,10),'min_samples_split':np.linspace(2,30,15,dtype=int),'random_state':[42]}]\n",
    "\n",
    "grid_search_forest = GridSearchCV(randomForest,grid_para_forest,scoring='r2',cv=5,n_jobs=-1)\n",
    "%time grid_search_forest.fit(x_train_rf,y_train_rf)\n",
    "\n",
    "best_forest_model = grid_search_forest.best_estimator_\n",
    "print(grid_search_forest.best_params_)\n",
    "\n",
    "Results_forest_no_drop = pd.DataFrame({'CV':grid_search_forest.best_score_,\n",
    "                       'Adjusted': diagnostics(best_forest_model,x_train_rf,y_train_rf),\n",
    "                       'Train':best_forest_model.score(x_train_rf, y_train_rf),\n",
    "                       'Test':best_forest_model.score(x_test_rf, y_test_rf)}, \n",
    "                              index = ['Random_forest_no_drop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract feature importances from the random forest\n",
    "feature_importance = list(zip(x_train.columns, best_forest_model.feature_importances_))\n",
    "dtype = [('feature', 'S10'), ('importance', 'float')]\n",
    "feature_importance = np.array(feature_importance, dtype=dtype)\n",
    "feature_sort = np.sort(feature_importance, order='importance')[::-1]\n",
    "name, score = zip(*list(feature_sort))\n",
    "pd.DataFrame({'name':name,'score':score}).plot.bar(x='name', y='score')\n",
    "feature_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the predictions of the random forest on the slightly reduced data set\n",
    "sub3 = pd.DataFrame(np.exp(grid_search_forest.predict(test)),index=test.index+1,columns=['SalePrice'])\n",
    "sub3.to_csv('sub3.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the predictions of the random forest on the complete data set\n",
    "sub6 = pd.DataFrame(np.exp(grid_search_forest.predict(test)),index=test.index+1,columns=['SalePrice'])\n",
    "sub6.to_csv('sub6.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting regressor using linear\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbm = GradientBoostingRegressor(verbose=1)\n",
    "\n",
    "grid_para_boost_lr = [{\n",
    "#     \"learning_rate\": np.linspace(start=0.01, stop=0.1, num=10),\n",
    "    \"n_estimators\": [100, 500],\n",
    "    \"min_samples_leaf\": range(1, 5),\n",
    "    \"min_samples_split\": np.linspace(start=2, stop=10, num=5, dtype=int),\n",
    "    \"random_state\": [42]}]\n",
    "grid_search_boost = GridSearchCV(gbm, grid_para_boost_lr, scoring='r2', cv=5, n_jobs=3)\n",
    "%time grid_search_boost.fit(x_train, y_train)\n",
    "\n",
    "best_boost_model = grid_search_boost.best_estimator_\n",
    "print(grid_search_boost.best_params_)\n",
    "\n",
    "Results_boost = pd.DataFrame({'CV':grid_search_boost.best_score_,\n",
    "                       'Adjusted': diagnostics(best_boost_model, x_train, y_train),\n",
    "                       'Train':best_boost_model.score(x_train, y_train),\n",
    "                       'Test':best_boost_model.score(x_test, y_test)}, \n",
    "                              index = ['Gradient_boosting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient boosting regressor using huber\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbm = GradientBoostingRegressor(loss = 'huber', verbose = 1, subsample = 0.9, learning_rate = 0.2)\n",
    "\n",
    "grid_para_boost_hu = [{\n",
    "    \"alpha\": np.linspace(start = 0.75, stop = 0.95, num = 10),\n",
    "#     \"learning_rate\": np.linspace(start=0.01, stop=0.1, num=10),\n",
    "    \"n_estimators\": [100, 300],\n",
    "    \"min_samples_leaf\": range(1, 5),\n",
    "    \"min_samples_split\": np.linspace(start=2, stop=10, num=5, dtype=int),\n",
    "    \"random_state\": [42]}]\n",
    "grid_search_boost = GridSearchCV(gbm, grid_para_boost_hu, scoring='r2', cv=5, n_jobs=3)\n",
    "%time grid_search_boost.fit(x_train, y_train)\n",
    "\n",
    "best_boost_model = grid_search_boost.best_estimator_\n",
    "print(grid_search_boost.best_params_)\n",
    "\n",
    "Results_boost_hubr = pd.DataFrame({'CV':grid_search_boost.best_score_,\n",
    "                       'Adjusted': diagnostics(best_boost_model, x_train, y_train),\n",
    "                       'Train':best_boost_model.score(x_train, y_train),\n",
    "                       'Test':best_boost_model.score(x_test, y_test)}, \n",
    "                              index = ['Gradient_boosting_hubr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "paramDict = [{'C':np.linspace(1,100,20),'gamma':np.linspace(1e-6,1e-2,10)}]\n",
    "\n",
    "grid_search_svr = GridSearchCV(svr, paramDict, cv=5, return_train_score = True, n_jobs=-1)\n",
    "%time grid_search_svr.fit(x_train,y_train)\n",
    "\n",
    "best_svr_model = grid_search_svr.best_estimator_\n",
    "print(grid_search_svr.best_params_)\n",
    "\n",
    "Results_svr = pd.DataFrame({'CV':grid_search_svr.best_score_,\n",
    "                       'Adjusted': diagnostics(best_svr_model, x_train, y_train),\n",
    "                       'Train':best_svr_model.score(x_train, y_train),\n",
    "                       'Test':best_svr_model.score(x_test, y_test)}, \n",
    "                              index = ['Svr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the predictions of the gradient boost regression\n",
    "sub9 = pd.DataFrame(np.exp(grid_search_boost.predict(test)),index=test.index+1,columns=['SalePrice'])\n",
    "sub9.to_csv('sub9.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"all results\"></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat([linear_model_results, Results_decisiontree, Results_forest, \n",
    "                         Results_forest_no_drop,\n",
    "                         Results_boost, Results_boost_hubr, Results_svr], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.to_csv(\"All_Results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
